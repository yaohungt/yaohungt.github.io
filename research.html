<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<link rel="icon" href="school.ico" type="image/x-icon" />
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Publications</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="research.html" class="current">Publications</a></div>
<div class="menu-item"><a href="./cv/hubert_cv.pdf">CV</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Publications</h1>
</div>
<p>*: indicating equal contribution or alphabetic ordering.</p>
<p><font size = 6> 2020 </font></p>
<ul>
<li><p><a href="https://arxiv.org/pdf/2005.12123.pdf">Feature Robust Optimal Transport for High-dimensional Data</a><br />
Mathis Petrovich*, Chao Liang*, Yanbin Liu, <b>Yao-Hung Hubert Tsai</b>, Linchao Zhu, Yi Yang, Ruslan Salakhutdinov, Makoto Yamada.<br />
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/pdf/2004.14198.pdf">Interpretable Multimodal Routing for Human Multimodal Language</a><br />
<b>Yao-Hung Hubert Tsai</b>*, Martin Q. Ma*, Muqiao Yang*, Ruslan Salakhutdinov, Louis-Philippe Morency.<br />
[<a href="https://github.com/martinmamql/Interpretable-Multimodal-Routing-for-Human-Multimodal-Language">Code</a>]</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/pdf/1910.10202.pdf">Complex Transformer: A Framework for Modeling Complex-Valued Sequence</a><br />
Muqiao Yang*, Martin Q. Ma*, Dongyu Li*, <b>Yao-Hung Hubert Tsai</b>, Ruslan Salakhutdinov.<br />
NeurIPS Science meets Engineering of Deep Learning Workshop (NeurIPS SEDL) 2019 (<font color="red">Oral</font>). <br />
International Conference on Acoustics, Speech and Signal Processing (ICASSP) 2020. <br />
[<a href="https://github.com/muqiaoy/dl_signal">Code</a>]</p>
</li>
</ul>
<ul>
<li><p><a href="https://openreview.net/forum?id=HJe6uANtwH">Capsules with Inverted Dot-Product Attention Routing</a><br />
<b>Yao-Hung Hubert Tsai</b>, Nitish Srivastava, Hanlin Goh, Ruslan Salakhutdinov.<br />
International Conference on Learning Representations (ICLR) 2020. <br />
[<a href="https://github.com/yaohungt/ml-capsules-inverted-attention-routing">Code (my maintained version)</a>] [<a href="https://github.com/apple/ml-capsules-inverted-attention-routing">Code (Apple's version)</a>]</p></p>
</li>
</ul>
<p><font size = 6> 2019 </font></p>
<ul>
<li><p><a href="https://arxiv.org/pdf/1909.02373.pdf">LSMI-Sinkhorn: Semi-supervised Squared-Loss Mutual Information Estimation with Optimal Transport</a><br />
Yanbin Liu*, Makoto Yamada*, <b>Yao-Hung Hubert Tsai</b>, Tam Le, Ruslan Salakhutdinov, Yi Yang.<br /></p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/pdf/1907.06288.pdf">Learning Neural Networks with Adaptive Regularization</a><br />
Han Zhao*, <b>Yao-Hung Hubert Tsai</b>*, Ruslan Salakhutdinov, Geoff Gordon.<br />
Neural Information Processing Systems (NeurIPS) 2019. <br />
[<a href="https://github.com/yaohungt/Adaptive-Regularization-Neural-Network">Code</a>] [<a href="https://www.youtube.com/watch?time_continue=56&v=RukTkXo56Jw">Talk</a>] [<a href="https://www.cs.cmu.edu/~hzhao1/papers/NIPS2019/adareg_poster.pdf">Poster</a>]  [<a href="https://www.cs.cmu.edu/~hzhao1/papers/NIPS2019/adareg_slides.pdf">Slides</a>]</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/pdf/1908.11775.pdf">Transformer Dissection: A Unified Understanding of Transformer's Attention via the Lens of Kernel</a><br />
<b>Yao-Hung Hubert Tsai</b>, Shaojie Bai, Makoto Yamada, Louis-Philippe Morency, Ruslan Salakhutdinov.<br />
Empirical Methods in Natural Language Processing (EMNLP) 2019. <br />
[<a href="https://github.com/yaohungt/TransformerDissection">Summary</a>] [<a href="https://www.dropbox.com/s/w9ch3n3cxen6oom/slide.pdf?dl=0">Slides</a>]</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/pdf/1906.00295.pdf">Multimodal Transformer for Unaligned Multimodal Language Sequences</a><br />
<b>Yao-Hung Hubert Tsai</b>*, Shaojie Bai*, Paul Pu Liang, J. Zico Kolter, Louis-Philippe Morency, Ruslan Salakhutdinov.<br />
Association for Computational Linguistics (ACL) 2019. <br />
[<a href="https://github.com/yaohungt/Multimodal-Transformer">Code</a>]</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/pdf/1907.01011.pdf">Learning Representations from Imperfect Multimodal Time Series Data via Tensor Rank Regularization</a><br />
Paul Pu Liang*, Zhun Liu*, <b>Yao-Hung Hubert Tsai</b>, Qibin Zhao, Ruslan Salakhutdinov, Louis-Philippe Morency.<br />
Association for Computational Linguistics (ACL) 2019.</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/pdf/1903.10547.pdf">Video Relationship Reasoning using Gated Spatio-Temporal Energy Graph</a><br />
<b>Yao-Hung Hubert Tsai</b>, Santosh Kumar Divvala, Louis-Philippe Morency, Ruslan Salakhutdinov, Ali Farhadi.<br />
Computer Vision and Pattern Recognition (CVPR) 2019. <br />
[<a href="https://github.com/yaohungt/GSTEG_CVPR_2019">Code</a>]</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/pdf/1906.02125.pdf">Strong and Simple Baselines for Multimodal Utterance Embeddings</a><br />
Paul Pu Liang*, Yao Chong Lim*, <b>Yao-Hung Hubert Tsai</b>, Ruslan Salakhutdinov, Louis-Philippe Morency.<br />
North American Chapter of the Association for Computational Linguistics (NAACL) 2019 (<font color="red">Oral</font>).</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/pdf/1806.06176.pdf">Learning Factorized Multimodal Representations</a><br />
<b>Yao-Hung Hubert Tsai</b>*, Paul Pu Liang*, Amir Zadeh, Louis-Philippe Morency, Ruslan Salakhutdinov.<br />
International Conference on Learning Representations (ICLR) 2019.</p>
</li>
</ul>
<ul>
<li><p><a href="https://openreview.net/pdf?id=BkG5SjR5YQ">Post Selection Inference with Incomplete Maximum Mean Discrepancy Estimator</a><br />
Makoto Yamada*, Denny Wu*, <b>Yao-Hung Hubert Tsai</b>, Hirofumi Ohta, Ruslan Salakhutdinov, Ichiro Takeuchi, Kenji Fukumizu.<br />
International Conference on Learning Representations (ICLR) 2019.</p>
</li>
</ul>
<ul>
<li><p><a href="https://ieeexplore.ieee.org/document/8703744">Transfer Neural Trees: Semi-Supervised Heterogeneous Domain Adaptation and Beyond</a><br />
Wei-Yu Chen, Tzu-Ming Harry Hsu, <b>Yao-Hung Hubert Tsai</b>, Yu-Chiang Frank Wang, Ming-Syan Chen.<br />
Transactions on Image Processing (TIP) 2019.</p>
</li>
</ul>
<p><font size = 6> 2018 </font></p>
<ul>
<li><p><a href="http://bayesiandeeplearning.org/2018/papers/123.pdf">Semi-Supervised Pairing via Basis-Sharing Wasserstein Matching Auto-Encoder</a><br />
Ziyin Liu, <b>Yao-Hung Hubert Tsai</b>*, Makoto Yamada, Ruslan Salakhutdinov. <br />
NeurIPS Bayesian Deep Learning Workshop (NeruIPS BDL) 2018. </p>
</li>
</ul>
<ul>
<li><p><a href="https://openreview.net/pdf?id=SkpC5K1vG">Selecting the Best in GANs Family: a Post Selection Inference Framework</a><br />
<b>Yao-Hung Hubert Tsai</b>*, Denny Wu*, Makoto Yamada*, Ruslan Salakhutdinov, Ichiro Takeuchi, Kenji Fukumizu. <br />
International Conference on Representation Learning Workshop (ICLR Workshop) 2018. </p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/pdf/1802.05408.pdf">Dependency Bottleneck in Auto-encoding Architectures: an Empirical Study</a><br />
Denny Wu*, Yixiu Zhao*, <b>Yao-Hung Hubert Tsai</b>*, Makoto Yamada, Ruslan Salakhutdinov. </p>
</li>
</ul>
<p><font size = 6> 2017 </font></p>
<ul>
<li><p><a href="https://arxiv.org/pdf/1703.05908.pdf">Learning Robust Visual-Semantic Embeddings</a><br />
<b>Yao-Hung Hubert Tsai</b>, Liang-Kang Huang, Ruslan Salakhutdinov.<br /> 
International Conference on Computer Vision (ICCV) 2017. </p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/pdf/1710.08347.pdf">Improving One-Shot Learning through Fusing Side Information</a><br />
<b>Yao-Hung Hubert Tsai</b>, Ruslan Salakhutdinov.<br />
NeurIPS Learning with Limited Labeled Data: Weak Supervision and Beyond (NeurIPS LLD) 2017.<br />
Bay Area Machine Learning Symposium (BayLearn) 2017 (<font color="red">Best Poster</font>).
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/pdf/1711.03167.pdf">Learning Markov Chain in Unordered Dataset</a><br />
<b>Yao-Hung Hubert Tsai</b>, Han Zhao, Ruslan Salakhutdinov, Nebojsa Jojic.<br />
NeurIPS Time Series Workshop (NeurIPS TSW) 2017 (<font color="red">Oral</font>).
</p>
</li>
</ul>
<p><font size = 6> 2016 </font></p>
<ul>
<li><p><a href="http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Tsai_Learning_Cross-Domain_Landmarks_CVPR_2016_paper.pdf">Learning Cross-Domain Landmarks for Heterogeneous Domain Adaptation</a><br />
<b>Yao-Hung Hubert Tsai</b>, Yi-Ren Yeh, Yu-Chiang Frank Wang.<br />
Computer Vision and Pattern Recognition (CVPR) 2016.<br />
[<a href="papers/CVPR_2016_sup.pdf">Supplementary</a>] [<a href="papers/CVPR_2016_pos.pdf">Poster</a>] [<a href="https://github.com/yaohungt/Cross-Domain-Landmarks-Selection-CDLS-">Code</a>]
</p>
</li>
</ul>
<ul>
<li><p><a href="https://ieeexplore.ieee.org/document/7569007">Unsupervised Domain Adaptation With Label and Structural Consistency</a><br />
Cheng-An Hou, <b>Yao-Hung Hubert Tsai</b>, Yi-Ren Yeh, Yu-Chiang Frank Wang.<br />
Transactions on Image Processing (TIP) 2016.</p>
</li>
</ul>
<ul>
<li><p><a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/view/11776/12135">Domain-Constraint Transfer Coding for Imbalanced Unsupervised Domain Adaptation</a><br />
<b>Yao-Hung Hubert Tsai</b>, Cheng-An Hou, Wei-Yu Chen, Yi-Ren Yeh, Yu-Chiang Frank Wang.<br />
Association for the Advancement of Artificial Intelligence (AAAI) 2016.</p>
</li>
</ul>
<ul>
<li><p><a href="http://mml.citi.sinica.edu.tw/papers/eccv2016.pdf">Transfer Neural Trees for Heterogeneous Domain Adaptation</a><br />
Wei-Yu Chen, Tzu-Ming Harry Hsu, <b>Yao-Hung Hubert Tsai</b>, Yu-Chiang Frank Wang, Ming-Syan Chen.<br />
European Conference on Computer Vision (ECCV) 2016.</p>
</li>
</ul>
<ul>
<li><p><a href="http://mml.citi.sinica.edu.tw/papers/ICASSP_2016_Tsai.pdf">Heterogeneous Domain Adaptation with Label and Structure Consistency</a><br />
<b>Yao-Hung Hubert Tsai</b>, Yi-Ren Yeh, Yu-Chiang Frank Wang.<br />
International Conference on Acoustics, Speech and Signal Processing (ICASSP) 2016.</p>
</li>
</ul>
<ul>
<li><p><a href="https://jakesabathia.github.io/paper/icme_final.pdf">Recognizing Heterogeneous Cross-Domain Data via Generalized Joint Distribution Adaptation</a><br />
Yuan-Ting Hsieh*, Shi-Yen Tao*, <b>Yao-Hung Hubert Tsai</b>, Yi-Ren Yeh, Yu-Chiang Frank Wang.<br />
International Conference on Multimedia and Expo (ICME) 2016 (<font color="red">Oral</font>).<br />
<a href="https://jakesabathia.github.io/paper/ICME-2016.pdf">[Slides]</a>
</p>
</li>
</ul>
<p><font size = 6> 2015 </font></p>
<ul>
<li><p><a href="https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Hsu_Unsupervised_Domain_Adaptation_ICCV_2015_paper.pdf">Unsupervised Domain Adaptation with Imbalanced Cross-Domain Data</a><br />
Tzu-Ming Harry Hsu, Wei-Yu Chen, Cheng-An Hou, <b>Yao-Hung Hubert Tsai</b>, Yi-Ren Yeh, Yu-Chiang Frank Wang.<br />
International Conference on Computer Vision (ICCV) 2015.</p>
</li>
</ul>
<p><font size = 6> 2014 </font></p>
<ul>
<li><p><a href="http://mml.citi.sinica.edu.tw/papers/ICIP_2014_Tsai.pdf">Person-Specific Domain Adaptation with Applications to Heterogeneous Face Recognition</a><br />
<b>Yao-Hung Tsai</b>*, Hung-Ming Hsu*, Cheng-An Hou, Yu-Chiang Frank Wang.<br />
International Conference on Image Processing (ICIP) 2014.</p>
</li>
</ul>
<ul>
<li><p><a href="http://media.ee.ntu.edu.tw/personal/pcwu/research/mmsp2014_spe/mmsp2014_spe.pdf">Stable Pose Tracking from a Planar Target with an Analytical Motion Model in Real-Time Applications</a><br />
Po-Chen Wu, <b>Yao-Hung Tsai</b>, Shao-Yi Chien.<br />
International Workshop on Multimedia Signal Processing (MMSP) 2014.</p>
</li>
</ul>
<div id="footer">
<div id="footer-text">
Pages generated by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>